{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Requires python 3.12\n",
    "pip install matplotlib mediapipe opencv-python scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter: A, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: B, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: C, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: D, Classification: 1\n",
      "Landmark detection rate: 1.0\n",
      "Letter: E, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: F, Classification: 3\n",
      "Landmark detection rate: 1.0\n",
      "Letter: G, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: H, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: I, Classification: 1\n",
      "Landmark detection rate: 1.0\n",
      "Letter: J, Classification: 1\n",
      "Landmark detection rate: 1.0\n",
      "Letter: K, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: L, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: M, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: N, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: O, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: P, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: Q, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: R, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: S, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: T, Classification: 0\n",
      "Landmark detection rate: 1.0\n",
      "Letter: U, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: V, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: W, Classification: 3\n",
      "Landmark detection rate: 1.0\n",
      "Letter: X, Classification: 1\n",
      "Landmark detection rate: 1.0\n",
      "Letter: Y, Classification: 2\n",
      "Landmark detection rate: 1.0\n",
      "Letter: Z, Classification: 1\n",
      "Landmark detection rate: 1.0\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './Datasets/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
    "TEST_DIR = './Datasets/asl-alphabet/asl_alphabet_test/asl_alphabet_test'\n",
    "\n",
    "# configuration for different methods\n",
    "GROUP = True\n",
    "VALIDATE = True\n",
    "\n",
    "landmark_dataset = []\n",
    "labels = []\n",
    "\n",
    "# load options for hand landmark detection\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Group letters into classifications based on the number of fingers raised\n",
    "# 0 is for a closed fist\n",
    "grouped_classifications = {\n",
    "    'A': 0,\n",
    "    'B': 0,\n",
    "    'C': 0,\n",
    "    'D': 1,\n",
    "    'E': 0,\n",
    "    'F': 3,\n",
    "    'G': 2,\n",
    "    'H': 0,\n",
    "    'I': 1,\n",
    "    'J': 1,\n",
    "    'K': 2,\n",
    "    'L': 2,\n",
    "    'M': 0,\n",
    "    'N': 0,\n",
    "    'O': 0,\n",
    "    'P': 2,\n",
    "    'Q': 2,\n",
    "    'R': 2,\n",
    "    'S': 0,\n",
    "    'T': 0,\n",
    "    'U': 2,\n",
    "    'V': 2,\n",
    "    'W': 3,\n",
    "    'X': 1,\n",
    "    'Y': 2,\n",
    "    'Z': 1,\n",
    "}\n",
    "\n",
    "individual_classifications = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    'G': 6,\n",
    "    'H': 7,\n",
    "    'I': 8,\n",
    "    'J': 9,\n",
    "    'K': 10,\n",
    "    'L': 11,\n",
    "    'M': 12,\n",
    "    'N': 13,\n",
    "    'O': 14,\n",
    "    'P': 15,\n",
    "    'Q': 16,\n",
    "    'R': 17,\n",
    "    'S': 18,\n",
    "    'T': 19,\n",
    "    'U': 20,\n",
    "    'V': 21,\n",
    "    'W': 22,\n",
    "    'X': 23,\n",
    "    'Y': 24,\n",
    "    'Z': 25,\n",
    "}\n",
    "\n",
    "classifications = None\n",
    "if GROUP:\n",
    "    classifications = grouped_classifications\n",
    "else:\n",
    "    classifications = individual_classifications\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='./hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE,\n",
    "    min_hand_detection_confidence=0,\n",
    "    min_hand_presence_confidence=0,\n",
    "    min_tracking_confidence=0)\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "    total_images = 0\n",
    "    no_landmarks = 0\n",
    "    for letter in os.listdir(DATA_DIR):\n",
    "        if letter in ['del', 'nothing', 'space']:\n",
    "            continue\n",
    "        for i, img_path in enumerate(os.listdir(os.path.join(DATA_DIR, letter))):\n",
    "            if VALIDATE and i % 20 != 0:\n",
    "                continue\n",
    "            total_images += 1\n",
    "            hand_landmarks = []\n",
    "\n",
    "            # Load image from file\n",
    "            mp_image = mp.Image.create_from_file(os.path.join(DATA_DIR, letter, img_path))\n",
    "\n",
    "            results = landmarker.detect(mp_image)\n",
    "\n",
    "            if results.hand_landmarks:\n",
    "                for landmark in results.hand_landmarks[0]:\n",
    "                    hand_landmarks.append(landmark.x)\n",
    "                    hand_landmarks.append(landmark.y)\n",
    "\n",
    "                landmark_dataset.append(hand_landmarks)\n",
    "\n",
    "                classification = classifications[letter]\n",
    "                labels.append(classifications[letter])\n",
    "            else:\n",
    "                no_landmarks += 1\n",
    "\n",
    "        print(f'Letter: {letter}, Classification: {classification}')\n",
    "        # print landmark detection rate\n",
    "        print(f'Landmark detection rate: {1-(no_landmarks / total_images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 83.84615384615385%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Convert the data to numpy arrays\n",
    "landmark_array = np.array(landmark_dataset)\n",
    "label_array = np.array(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(landmark_array, label_array, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: './Datasets/asl-alphabet/asl_alphabet_test/asl_alphabet_test\\\\J_test.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m letter \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(letters)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# pick random image\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m img_path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mletter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load image from file\u001b[39;00m\n\u001b[0;32m     15\u001b[0m mp_image \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mcreate_from_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TEST_DIR, letter, img_path))\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: './Datasets/asl-alphabet/asl_alphabet_test/asl_alphabet_test\\\\J_test.jpg'"
     ]
    }
   ],
   "source": [
    "# example showing model inference and visualization\n",
    "\n",
    "# pick random image in dataset\n",
    "# create array of letters\n",
    "\n",
    "letters = [letter for letter in os.listdir(TEST_DIR)]\n",
    "\n",
    "# pick random letter\n",
    "letter = np.random.choice(letters)\n",
    "\n",
    "# pick random image\n",
    "img_path = np.random.choice(os.listdir(os.path.join(TEST_DIR, letter)))\n",
    "\n",
    "# Load image from file\n",
    "mp_image = mp.Image.create_from_file(os.path.join(TEST_DIR, letter, img_path))\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "    results = landmarker.detect(mp_image)\n",
    "    if results.hand_landmarks:\n",
    "        hand_landmarks = []\n",
    "        for landmark in results.hand_landmarks[0]:\n",
    "            hand_landmarks.append(landmark.x)\n",
    "            hand_landmarks.append(landmark.y)\n",
    "\n",
    "        prediction = model.predict([hand_landmarks])\n",
    "        print(f'Predicted class: {prediction[0]}, Actual: {classifications[letter]}')\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, letter, img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # draw landmarks with small radius\n",
    "        for landmark in results.hand_landmarks[0]:\n",
    "            cv2.circle(img, (int(landmark.x * img.shape[1]), int(landmark.y * img.shape[0])), 2, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No hand landmarks detected')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 62.69230769230769%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "distances = []\n",
    "for hand in landmark_array:\n",
    "    distances.append([\n",
    "        np.linalg.norm(hand[0:2] - hand[8:10]),\n",
    "        np.linalg.norm(hand[0:2] - hand[12:14]),\n",
    "        np.linalg.norm(hand[0:2] - hand[16:18]),\n",
    "        np.linalg.norm(hand[0:2] - hand[20:22]),\n",
    "    ])\n",
    "\n",
    "distances = np.array(distances).reshape(len(landmark_array), -1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(distances, label_array, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = svm_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('Model accuracy: {}%'.format(accuracy * 100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
