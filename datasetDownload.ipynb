{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_kaggle_dataset(dataset_name, output_path):\n",
    "    \"\"\"Downloads a Kaggle dataset.\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    kaggle_path = \"/opt/anaconda3/envs/my-env/bin/kaggle\"  # Replace with your kaggle executable path\n",
    "    command = f\"{kaggle_path} datasets download -d {dataset_name} -p {output_path} --unzip\"\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "    print(f\"Dataset downloaded to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
      "License(s): GPL-2.0\n",
      "Downloading asl-alphabet.zip to ./Datasets/asl-alphabet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1.02G/1.03G [00:47<00:00, 22.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.03G/1.03G [00:48<00:00, 22.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: ./Datasets/asl-alphabet\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"grassknoted/asl-alphabet\"\n",
    "output_path = \"./Datasets/asl-alphabet\"\n",
    "download_kaggle_dataset(dataset_name, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/prathumarikeri/american-sign-language-09az\n",
      "License(s): CC-BY-SA-4.0\n",
      "Downloading american-sign-language-09az.zip to ./Datasets/american-sign-language-09az\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 993M/993M [00:43<00:00, 23.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset downloaded to: ./Datasets/american-sign-language-09az\n"
     ]
    }
   ],
   "source": [
    "dataset_name2 = \"prathumarikeri/american-sign-language-09az\"\n",
    "output_path2 = \"./Datasets/american-sign-language-09az\"\n",
    "download_kaggle_dataset(dataset_name2, output_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_path = \"Datasets/asl-alphabet/\"\n",
    "train_path = Path(base_path) / \"asl_alphabet_train\" / \"asl_alphabet_train\"\n",
    "test_path = Path(base_path) / \"asl_alphabet_test\" / \"asl_alphabet_test\"\n",
    "output_path = \"Datasets/Processed_asl_alphabet\"\n",
    "\n",
    "# Create output directories\n",
    "output_train_path = Path(output_path) / \"train\"\n",
    "output_test_path = Path(output_path) / \"test\"\n",
    "output_train_path.mkdir(parents=True, exist_ok=True)\n",
    "output_test_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocessing complete! Train and test data organized in Datasets/Processed_asl_alphabet.\n"
     ]
    }
   ],
   "source": [
    "# List of folders to keep (A-Z only)\n",
    "valid_classes = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "\n",
    "# Process training data\n",
    "for cls in valid_classes:\n",
    "    cls_train_path = train_path / cls\n",
    "    cls_output_train_path = output_train_path / cls\n",
    "    cls_output_test_path = output_test_path / cls\n",
    "\n",
    "    cls_output_train_path.mkdir(parents=True, exist_ok=True)\n",
    "    cls_output_test_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all images in the class folder\n",
    "    images = list(cls_train_path.glob(\"*.jpg\"))\n",
    "    \n",
    "    # Shuffle and split into train and test sets\n",
    "    split_index = int(0.8 * len(images))\n",
    "    train_images = images[:split_index]\n",
    "    test_images = images[split_index:]\n",
    "\n",
    "    # Move files to respective directories\n",
    "    for img in train_images:\n",
    "        shutil.copy(img, cls_output_train_path / img.name)\n",
    "    for img in test_images:\n",
    "        shutil.copy(img, cls_output_test_path / img.name)\n",
    "\n",
    "# Process test data (adding remaining single images for validation)\n",
    "for cls in valid_classes:\n",
    "    test_img_path = test_path / f\"{cls}.jpg\"\n",
    "    if test_img_path.exists():\n",
    "        shutil.copy(test_img_path, output_test_path / cls / test_img_path.name)\n",
    "\n",
    "print(f\"Dataset preprocessing complete! Train and test data organized in {output_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "my-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
